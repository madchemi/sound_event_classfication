{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"bMwnIKDTjsGp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728655865727,"user_tz":-540,"elapsed":10567,"user":{"displayName":"윤희준_21_1697","userId":"12449811895183228834"}},"outputId":"9c6bdc7d-d93e-43d9-9d3b-a873483ea4e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["!pip3 install torch"]},{"cell_type":"code","source":["!pip3 install torchvision"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9knG_I418Hjd","executionInfo":{"status":"ok","timestamp":1728655872533,"user_tz":-540,"elapsed":6809,"user":{"displayName":"윤희준_21_1697","userId":"12449811895183228834"}},"outputId":"ebd762c3-c409-4b4e-d6dc-797afc32eb04"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: torch==2.4.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.4.1+cu121)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.1->torchvision) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.1->torchvision) (1.3.0)\n"]}]},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.functional as F\n","import torch.optim as optim\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import sklearn\n","import random\n","import os\n","import scipy\n","\n","from scipy import signal\n","from scipy.io import wavfile\n","from unicodedata import normalize\n","import librosa.display\n","import librosa"],"metadata":{"id":"EIRMdJp98cMZ","executionInfo":{"status":"ok","timestamp":1728655883219,"user_tz":-540,"elapsed":10699,"user":{"displayName":"윤희준_21_1697","userId":"12449811895183228834"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["추출하는 데이터의 크기: (40,174)\n","최대 패딩 사이즈: 174\n"],"metadata":{"id":"_UuLSQ2GPK6P"}},{"cell_type":"code","source":["#Feature extraction function\n","\n","def extract_feature(file_name):\n","  print('file name : ', file_name)\n","\n","  try:\n","    audio,smaple_rate = librosa.load(file_name, res_tpye='kaiser_fast')\n","    #res_type이 뭐야 ?\n","    mfccs = libsora.feature.mfcc(y=audio, sr = sample_rate, n_mfcc = 40)\n","    padd_width = max_pad_len - mfccs.shape[1] # 음성의 크키이기 때문에. 0은 시간에 대한 값인듯.\n","    mfccs = np.pad(mfccs, pad_width=((0,0),(0,pad_width),mode = 'constant'))\n","  except Exception as e:\n","        print(\"Error encountered while parsing file: \", file_name)\n","        print(e);\n","        return None\n","\n","    #np.pad(array, pad_width, mode = 'constant', **kwargs:\n","    # array: padding할 array, pad_width: 각 축에 padding에 사용할 숫자들(x,y), mode -> padding을 어떤 것으로 할지,"],"metadata":{"id":"ymOUXi4ePZqP","colab":{"base_uri":"https://localhost:8080/","height":106},"executionInfo":{"status":"error","timestamp":1728655886630,"user_tz":-540,"elapsed":564,"user":{"displayName":"윤희준_21_1697","userId":"12449811895183228834"}},"outputId":"2381a801-0c22-45a5-b49e-4e1844ff851c"},"execution_count":4,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax. Maybe you meant '==' or ':=' instead of '='? (<ipython-input-4-22bbcf5d9a67>, line 11)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-22bbcf5d9a67>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    mfccs = np.pad(mfccs, pad_width=((0,0),(0,pad_width),mode = 'constant'))\u001b[0m\n\u001b[0m                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Maybe you meant '==' or ':=' instead of '='?\n"]}]},{"cell_type":"code","source":["#경로 설정 및\n","\n","full_dataset_path = ''\n","metadata = pd.read_csv(\"\")\n","features =[]\n","\n","for index, row in metadata.iterrows():\n","   file_name = os.path.join(os.path.absapth(full_dataset_path),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n","\n","\n","          class_label = row[\"classID\"]\n","   data = extract_feature(file_name)\n","   features.append([data, class_label])\n","\n","featuresdf = pd.DataFrame(features, columns = ['features','class_label'])\n","\n"],"metadata":{"id":"_WidyCObVS55"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_dir = '/content/drive/MyDrive/gist_공모전/archive/Audio Wise V1.0-20220916T202003Z-001'\n","\n","\n","\n","\n","\n","for filename in os.listdir(data_dir):\n","  #filename = normalize('NFC',filename) # Normal to C(canonical, 정규화된 형태로 만듬. 유티코드는 안에 또 갈라지는 경우(decomposit)가 있어서, 정리해둠?)\n","\n","    if '.wav' not in filename in filename: #왜 이렇게 씀?\n","      continue\n","    wav, sr = librosa"],"metadata":{"id":"fdz4LpcBLDyQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mel Frequency Cepstral Coefficient\n","\n","\"\"\"\n","소리의 고유한 특징을 나타내는 수치를 입력할 수 있음.\n","\n","\n","\n","\n","\"\"\"\n","# 음성파일 길이가 같아지도록 패딩처리함.\n","pad1d = lambda a, i: a[0: i] if a.shape[0] > i else np.hstack((a, np.zeros(i-a.shape[0])))\n","pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))\n","\n"],"metadata":{"id":"EY5W47-YDl0F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train data 삽입\n"],"metadata":{"id":"JEt4YZV1J97L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"FxRZ1k_MJ-Ho"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_dir_train =\"\"\n","data_dir_test =\"\"\n","\n","train_data = datasets.ImageFolder(data_dir_train, transform = transforms.Compose([transforms.ToTensor(),\n","                                                                                  transforms.Normalize((0.1307,),(0.3081,))])\n","train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size =50, shuffle = True)\n","\n","test_data = datasets.ImageFolder(data_dir_test, transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize(())]))\n","\n","\n","\n","\n","\n"],"metadata":{"id":"sK7ckNS2GKXU"},"execution_count":null,"outputs":[]}]}